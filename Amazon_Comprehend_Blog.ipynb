{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7576b33",
   "metadata": {},
   "source": [
    "# An Evaluation of Amazon Comprehend Under the Context of Professional Communication via Email \n",
    "Group Member: Flora Chen, Olivia Lin, Tong Bai, Uziel Rios, Walter Avila"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ccd842",
   "metadata": {},
   "source": [
    "## Meeting with the Team\n",
    "### **Flora Chen:**\n",
    "<img src = 'https://drive.google.com/uc?export=view&id=1IquZ7nZ4jdIizEbVSZ4xSRAogjbpaslw' width = 300>\n",
    "\n",
    "Flora is a junior double majoring in Computer Science and Quantitative Science-Economics. She enjoys baking and skating in her free time. She is an international student finding it difficult to grasp the true meaning of professional texts.\n",
    "\n",
    "### **Olivia Lin:**\n",
    "<img src = 'https://drive.google.com/uc?export=view&id=1VqCWkyE4awrv1v0nffThhJnCK0P42TNs' width = 300>\n",
    "\n",
    "Olivia is a junior double major in Business and Quantitative Sciences. She loves dancing, baking, and travelling during her spare time. She is also a member of two dance clubs on campus called “Mulan” and “Blaez.”\n",
    "\n",
    "### **Tong Bai:**\n",
    "<img src = 'https://drive.google.com/uc?export=view&id=1qS77vVe5fqX9WgV5FT39ySLeSOu5cNI8' width = 300>\n",
    "\n",
    "Tong is a junior majoring in Applied Mathematics and Statistics with a minor in German Studies. She is an international student that always feels struggled to read and write emails, in English and German. She plans to be a data analyst after graduating. You can find her Lindedin [here](https://www.linkedin.com/in/tong-bai-6156b4227/).\n",
    "\n",
    "### **Walter Avila:**\n",
    "<img src = 'https://drive.google.com/uc?export=view&id=1BkDJ8ksD5K8VhoWKgrvE5qVKVxUZZq0a' width = 300>\n",
    "\n",
    "Walter is a senior at the Emory College of Arts and Sciences majoring in QSS with a biology concentration. He plans to enter the biological and ecological informatics fields after graduating. In his free time, he enjoys playing basketball, roller skating, and going on long walks. You can find his Linkedin [here](https://www.linkedin.com/in/walter-avila-19a2101a1/). \n",
    "\n",
    "### **Uziel Rios:**\n",
    "<img src = 'https://drive.google.com/uc?export=view&id=1nfTPtKfx60JGH4JviW_VszQMhE-YZCrU' width = 300>\n",
    "\n",
    "Uziel is a senior at the Emory College of Arts and Sciences majoring in Applied Mathematics and Statistics. He plans on entering the data science/analytics field after graduating. In his free time, he enjoys working out, watching shows, and playing video games."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a6b37f",
   "metadata": {},
   "source": [
    "## Project Background\n",
    "E-mail is the most widely used communication platform in professional environments, with over 319.6 billion e-mails having been sent per day in 2021 (**Table 1**). According to a 2021 survey conducted by the Radicati Group — a technology research firm — e-mail is the principal communication medium for professionals, with 85% of respondents saying they use e-mail regularly for work.**[1]** However, the e-mail platform is not limited to businesses; it is also the most commonly used communication tool among college students. A 2020 survey from Educause, a nonprofit researching technology in higher education, found that 87% of students reported using e-mail for academic purposes.**[2]** This extensive student e-mail usage is because e-mail provides reliable ways for college students to communicate with their professors, peers, faculty, and other professionals.\n",
    "\n",
    "<img src = 'https://drive.google.com/uc?export=view&id=1-LsK4osIangPaI5hKYaxlmhJH9iWyCet' width = 550>\n",
    "\n",
    "**Table 1**: Worldwide Daily Email Traffic in billions. 2021 consists of recorded data from that year. The daily traffic values for 2022 to 2025 are predicted values. Source: Email Statistics Report, 2021-2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479017a7",
   "metadata": {},
   "source": [
    "For example, students can contact professors to discuss coursework, receive important information from their school regarding class schedule updates and campus events, and network with professionals in their field to apply for opportunities. Overall, college students depend on using e-mail to communicate with peers and professionals to help them succeed academically and professionally.\n",
    "\n",
    "However, despite being the core communication network for college students, e-mail presents two issues that can frustrate students and other users alike. The first issue is that tones and sentiments in e-mails can be easily misconveyed and misinterpreted, which may muddy important information, primarily because emotions and tones are more difficult to express and understand in text formats, especially e-mail. According to a study published in the Journal of Personality and Social Psychology, Kruger et al., 2005, found that individuals tend to misinterpret the tone of e-mails, reporting that people are more likely to interpret e-mails as negative or neutral rather than positive, even when the sender intended to convey a positive tone.**[3]**  \n",
    "\n",
    "Misinterpreting and misunderstanding sentiments in e-mails is a common obstacle for us college students. Sometimes, our professors, mentors, and other professionals with whom we want to maintain professional relationships may express ambiguous sentiments and tones in e-mails. This can be difficult, as sarcasm, inappropriate negativity, and other unprofessional sentiments may confound important information being communicated by the sender.  \n",
    "\n",
    "For example, let’s say an undergraduate research student messed up on an experiment for the third time. Frustrated, their principal investigator (PI) e-mails them, expressing their disappointment, and sarcastically says, “Why not repeat the experiment for the millionth time? Surely, you can’t mess up this time.” The student may be too shy to respond and believes their PI wants them to redo the experiment. However, from the PI’s perspective, they are just being sarcastic. So, the student eventually repeats the experiment, successfully this time, but is still met with their PI’s frustration for performing experimentation without their approval. In this scenario, an unclear e-mail sentiment led to a professional conflict that could have been easily avoided had the PI expressed their sentiments more clearly and professionally. \n",
    "\n",
    "Furthermore, such unclear sentiments can be more confusing when the e-mail recipient comes from a different culture, nation, language, or background from the sender. These sociocultural differences may amplify confusion which may more frequently result in scenarios similar to the one above. In our group, the international students hailing from various regions in mainland China in this group can attest to this: “Whenever my professor sends me an email, I always have a hard time guessing the tone and emotion behind the email. Is she satisfied with my work? What does “interesting idea” mean? Is this a good thing or a bad thing?” “Sometimes my professor gives me a comment, and I just don’t understand what he wants or his attitude.” “I got a message from my HR, and I spent an hour there wondering if that’s a positive or negative message.” \n",
    "\n",
    "The second challenge e-mails pose is that senders may send text-dense e-mails, making it difficult for the recipient to digest the significant and vital points. For example, let’s say a student was accepted to a summer research program and is being e-mailed important details about housing, payments, and program expectations for the participants; however, the e-mail contains almost 500 words. This lengthy e-mail may contain unfamiliar jargon or idioms that may be difficult to understand, especially if the recipient comes from a different sociocultural background. Reading this e-mail would be taxing, and human error could lead the reader to overlook critical information. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e636b892",
   "metadata": {},
   "source": [
    "## Project Introduction\n",
    "Fortunately, there has been recent work on developing artificial intelligence (AI) methods to comprehend tones and sentiments and summarize important information in all kinds of texts. Specifically, Amazon Web Services (AWS) provides Amazon Comprehend, a natural-language processing (NLP) service that uses machine learning (ML) to detect valuable insights and connections in text.**[4]** This ML service presents the possibility to more accurately and algorithmically uncover tones, sentiments, and other important information in text from e-mails. As college students from different backgrounds seeking to navigate through complex emotions and tones and information-dense paragraphs in e-mails, this automatic service may serve as a valuable tool in the future to help us better comprehend e-mails. \n",
    "\n",
    "Therefore, in this project, we will use and test three features from AWS’ Amazon Comprehend service(which will be introduced more specifically in the tutorial): \n",
    "* Sentiment Analysis: Determines the overall sentiment of a given text, outputting positive, negative, or neutral, a confidence score between 0 and 1 for this rating.\n",
    "* Targeted Sentiment Analysis: Determines sentiment expressed toward particular objects in a sentence. \n",
    "* Entity recognition: Returns the named entities (“People,” “Places,” “Locations,” etc.) in a sentence\n",
    "\n",
    "Specifically, we will test these features on sentences from e-mails that are personally relevant to us. We aim to use these features because they will return the key sentiments and entities in our e-mails’ sentences. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf325e1d",
   "metadata": {},
   "source": [
    "## What is Amazon Comprehend\n",
    "AWS Comprehend is a natural language processing (NLP) service provided by Amazon Web Services (AWS). It uses machine learning algorithms to extract insights from unstructured text data such as emails, social media posts, and documents. With AWS Comprehend, you can analyze text data to gain valuable insights about customer feedback, market trends, and more.\n",
    "\n",
    "Amazon Comprehend can perform a range of NLP tasks including:\n",
    "- Detecting the dominant language\n",
    "- Detecting named entities\n",
    "- Detecting key phrases\n",
    "- Determining sentiment\n",
    "- Analysis for targeted sentiment\n",
    "- Detecting syntax\n",
    "- Async analysis for event detection\n",
    "- Async analysis for topic modeling\n",
    "\n",
    "We created a tutorial for Amazon Comprehend. You can follow this [walkthrough](https://github.com/Flora-Chen6/qtm350_project/blob/main/Amazon-Comprehend-Tutorial.ipynb) to use Amazon Comprehend APIs on AWS CLI. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c0eecd",
   "metadata": {},
   "source": [
    "## Project Architecture\n",
    "\n",
    "The architecture diagram below shows the specific steps of the architecture. We first store all of our input text data into a S3 bucket. Then we initiate a notebook instance in Sagemaker. By calling the bucket, we pass the data stored in the bucket into Amazon Comprehend, which we output for our following analysis. In the end, we pushed our analysis and results to a GitHub repository. \n",
    "\n",
    "<img src = 'https://drive.google.com/uc?export=view&id=12L40O9VXva0xjLXJADE1TZ2p8c5C3Cl_\n",
    "' width = 560>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db84ec01",
   "metadata": {},
   "source": [
    "## Data Collection\n",
    "We begin our investigation with the **entity recognition** tool on 15 individual sentences pulled from Walter’s e-mails. He was recently accepted to a summer fellowship program in Oregon and experienced a recent knee injury leaving him to attend multiple orthopedist appointments. Therefore, he has received several e-mails from his program and orthopedist that are dense with essential details such as monetary and medical terminology. After quick Google searches, many of these terms in the sentences can be easily understood. However, sifting through dozens of lexicon words in larger e-mails may be time-consuming and difficult. As such, these emails present complex enough sentences that may prove challenging to the AWS entity analysis. Seeing how AWS performs on these kinds of sentences will help us gauge its usefulness and reliability when it comes to extracting important objects from e-mails with countless sentences and terminology terms. The e-mail sentences we use are sentences from e-mails containing communications from the Oregon program, injury-related e-mails, and an Emory e-mail sent back in March 2020 informing the student body of the move to remote learning.\n",
    "\n",
    "Then, we continue our investigation with the **sentiment analysis** feature. Specifically, we feed ten of Flora’s e-mails and ten individual sentences from Tong’s and Olivia’s emails into this feature, which outputs an overall sentiment for each e-mail and each sentence and a confidence score between 0 and 1 in that sentiment rating. These e-mails contain Linkedin posts embedded in the e-mail, assignment updates from professors, course-enrollment e-mails, and e-mails stating whether or not Flora was accepted to a particular program. She chose these e-mails because they each have a mix of sentiments and emotions being expressed, which are not always clear to the reader. Also, she chose both whole emails and individual sentences to test the performance of AWS Comprehend on the document level and sentence level. \n",
    "\n",
    "Afterward, we conclude our analysis with the **targeted sentiment analysis** feature. Tong and Olivia chose 15 sentences from their emails as the data. These emails include announcements from professors, updates from different programs regarding candidacy, and communications with professors. From those, 10 sentences are the same as the data we used for sentiment analysis for the purpose of comparing these two AWS Comprehend services. To be more specific, we want to have an understanding of the relationship between the sentiment score of the sentence and the sentiment score of each entity. Besides, we also include 5 more sentences to enlarge the dataset and add more controversial sentences that contain vague emotions.\n",
    "\n",
    "Our data can be found [here](https://github.com/Flora-Chen6/qtm350_project/tree/main/Test_Data). We then upload all our data to our S3 buckets to be used in SageMaker."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b242da",
   "metadata": {},
   "source": [
    "## Entity Recognition\n",
    "### Hypotheses\n",
    "Entity recognition will struggle to detect all entities within a sentence but will have moderate to strong performance on accurately classifying entities. \n",
    "### Experiement\n",
    "We begin our analysis with AWS’ entity recognition. AWS states, “An entity is a textual reference to the unique name of a real-world object such as people, places, and commercial items, and to precise references to measures such as dates and quantities.” An example sentence they provide is, “John moved to 1313 Mockingbird Lane in 2012,\" where the output for “John,” “1313 Mockingbird Lane,” and “2012” will be “PERSON,” “Location,” and “DATE,” respectively. Furthermore, each AWS-outputted entity has a confidence score between 0 and 1, which indicates how confident Amazon Comprehend is in that it correctly detected the entity type.**[5]** Shown below is a figure detailing all entity types, such as “COMMERCIAL_ITEM,” “EVENT,” “DATE,” and “PERSON.”\n",
    "\n",
    "We tested this feature on 15 sentences from Walter’s e-mails to see how accurately AWS Comprehend identifies entities in e-mail sentences dense with terminology that was not immediately clear to Walter when he first read them, such as monetary and medical terminology. Seeing how accurate AWS Comprehend is will not only, but will also be useful to Walter in ensuring he fully understands the information being communicated in the e-mails he has received. \n",
    "\n",
    "We then input these sentences into the entity recognition feature. Our code can be found [here](https://github.com/Flora-Chen6/qtm350_project/blob/main/Codes/Amazon_Comprehend_Entity_Detection_Test.ipynb). AWS outputted .json file containing the entities and their labels, which we then organized into a table. We added a column to this table containing our expected output/label for each entity AWS identified. Our result sheet can be found [here](https://github.com/Flora-Chen6/qtm350_project/blob/main/Result/Entity%20Expected%20%26%20Actual%20Output.xlsx), which contains the AWS and our expected outputs for each sentence, as well as the confidence scores for each identified and categorized entity. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d00f37",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3055000d",
   "metadata": {},
   "source": [
    "AWS entity recognition outputted a table with each entity and its type for each sentence. We added the expected output label for each sentence entity next to the AWS outputted label (**Table 1**).\n",
    "\n",
    "We created three metrics to assess AWS’ text recognition’s performance: 1. The proportion of the expected entities that AWS correctly identified, 2—the proportion of these correctly identified entities that match the expected entity type, and 3. The product of these two proportions is a measure of AWS’ overall performance on each sentence. Figure WA below plots these metrics for each of the 15 e-mail sentences we fed AWS’ text recognition. \n",
    "\n",
    "The left panel plots metric 1 for each sentence. An example that illustrates this metric: in sentence 1, Walter identified ten entities, whereas AWS’ entity recognition only correctly identified 1 entity, MRI. The only other entity that AWS identified for that sentence was “chondral,” which is not an entity but an adjective. Therefore, the metric 1 proportion for this sentence is 1/10. The x-axis shows the sentence ID of each sentence, and the y-axis shows this proportion. \n",
    "\n",
    "The right panel shows metric 2 for each sentence. An example that illustrates this metric: recall that AWS recognized only two entities in sentence 1: “MRI” and “Chondral;” however, only the former entity was a correctly identified entity. AWS labeled “MRI” as “OTHER,” and the expected output was also “OTHER.” These matched each other; therefore, the resultant proportion of correctly identified entities that were correctly classified is 1/1 = 1. We label this second as “accuracy” on the y-axis.\n",
    "\n",
    "Finally, the bottom panel shows metric 3 for each sentence. This metric is the product of metrics 1 and 2 which we denote as the model’s overall performance of identifying and classifying entities in each sentence. Like metrics 1 and 2, this metric’s range is between 0 and 1, inclusively. \n",
    "\n",
    "The average values for metrics 1, 2, and 3 were 0.27, 0.77, and 0.24, respectively, with standard deviations of 0.20, 0.34, and 0.18. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb0a714",
   "metadata": {},
   "source": [
    "<img src = 'https://drive.google.com/uc?export=view&id=1V_cjAAM6Yb5BaYY1NeTUep3zSnLYxb4L' width = 400>\n",
    "\n",
    "**Table 1**: The expected number of entities in each sentence and the actual number of entities from the output of AWS Comprehend\n",
    "\n",
    "<img src = 'https://drive.google.com/uc?export=view&id=1j3wOJY9mhY_6x7Rf2yQmwa-d_LPAjqtu' width = 600>\n",
    "\n",
    "**Figure 1**: The left panel (a) shows metric 1, which is the proportion of correctly identified entities by the AWS entity recognition system to the total number of entities identified by Walter. The right panel (b) shows metric 2, which is the proportion of correctly classified entities by the AWS system to the total number of entities identified by AWS. The bottom panel (c) shows metric 3, which is the product of metrics 1 and 2 which we denote as overall performance. The x-axis represents the sentence ID, and the y-axis represents the respective metric."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f671983",
   "metadata": {},
   "source": [
    "### Conclusions and Discussion:\n",
    "First, on average, only 27% of entities in a sentence were correctly identified. This means that AWS text recognition could not identify a sufficient number of nouns and items from all of our sentences. One example is sentence number 3; this text came from an e-mail from my orthopedic clinic, telling me to bring a physical report containing the results of one or more procedures they performed on me. Nouns and objects mentioned in this e-mail were “hand,” “provider,” “report,” “disk,” “CT,” “MRI,” and “images,” which did not appear in the output but were essential objects in the sentence. Instead, only “EMG” and “BOTH of these items” appeared in what AWS generated. \n",
    "\n",
    "However, for those entities that AWS did correctly identify, it performed strongly, averaging a 77% entity classification accuracy. In the end, however, once each accuracy was multiplied by its corresponding proportion of entities correctly identified, the average performance turned out to be 18%. \n",
    "\n",
    "Overall, the generated outputs from AWS text recognition differed from what we expected. AWS struggled to find more than half of all entities within our sentences but made up for it with high classification accuracy for those entities that were correctly identified. However, in the end, the low entity identification proportion brings down the average performance of this model for our sentences.\n",
    "\n",
    "Therefore, AWS entity recognition does not stand up to our expectations for jargon and lexicon-dense e-mail sentences like the ones we inputted, which contain important information for the reader that they may gloss over or struggle to understand. So, we would recommend using something other than this service for e-mails containing sentences similar to the ones we inputted. \n",
    "\n",
    "An additional concern regarding AWS entity recognition is the somewhat limited hierarchy of entity types. At least for our sentences, there are no types such as “legal document,” “body part,” or “medical procedure,” to name a few. As such, many of these kinds of words and entities will be classified into the rather vague “OTHER” type. This further corroborates our claim that this entity recognition service is not a solid algorithm for identifying and classifying nouns in information-packed sentences.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5ea275",
   "metadata": {},
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d21d29c",
   "metadata": {},
   "source": [
    "### Hypotheses\n",
    "AWS Comprehend Sentiment Analysis will be able to correctly label the overall sentiment label of the sentences and whole emails, but its confidence score might vary from the expected confidence score. Also, it would perform better on whole emails compared to individual sentences, since whole emails provide it with more contexts and more elements to be analyzed.\n",
    "\n",
    "### Experiment\n",
    "We continue our analysis with AWS sentiment recognition. We are able to use Amazon comprehend to determine the sentiment of content in UTF-8 encoded text documents. Our code to process the data can be found [here](https://github.com/Flora-Chen6/qtm350_project/blob/main/Codes/Amazon_Comprehend_Sentiment_Analysis_Test.ipynb).\n",
    "\n",
    "We also labeled the data manually to get the expected output of both the whole emails and the individual sentences. All 5 people in our group provided a sentiment score for each piece of data by first labeling it as \"positive\", \"negative\", or \"neutral\" and then giving it a confidence score based on how positive/negative/neutral we think this sentence is. \n",
    "\n",
    "After this, we organized the .json output file into a table and combined it with our manual labeling. Our output and expected output for individual sentences can be found [here](https://github.com/Flora-Chen6/qtm350_project/blob/main/Result/Sentiment_individual_sentence.xlsx). Our output and expected output for whole emails can be found [here](https://github.com/Flora-Chen6/qtm350_project/blob/main/Result/Sentiment_whole_email.xlsx).\n",
    "\n",
    "### Analysis\n",
    "Before diving into analysis, we first cleaned the data. The sentiment “Mixed” is identified by AWS when values of the three sentiments “Negative”, “Positive” and “Neutral” do not differ a lot. However, having a “Mixed” sentiment poses difficulty for us to measure the accuracy. Therefore, we replaced all “Mixed” sentiments by the sentiment that has the highest score among the three and used its corresponding score for comparison. For easier comparison and to ease computational difficulty, all the sentiment scores are rounded up to three decimal digits. \n",
    "\n",
    "We use all group member’s labelings to generate expected output, sentiments that one does not select are treated to have a score of 0. The sentiment that has the highest average score and the corresponding average score are selected to be the expected output. \n",
    "\n",
    "The expected score is calculated based on all group member’s labelings. If the actual sentiment is inconsistent with the expected sentiment, the individual score would be 0. Otherwise, we calculated the individual score as well as accuracy for each sentence/paragraph using the metrics shown below. First, we will have the individual score. Then, the score will be averaged for all sentences and whole emails to get an accuracy score of AWS Comprehend Sentiment Analysis for individual sentences and whole documents.\n",
    "\n",
    "<img src = 'https://drive.google.com/uc?export=view&id=1NK1-wSUQmo2M6j9lfS1lLx4GErLkHdQc' width = 500>\n",
    "\n",
    "                                   Figure 2: The Metrics to Measure Accuracy\n",
    "\n",
    "### Results\n",
    "For whole emails, 6 out of 10 sentiments are correctly identified while only 3 out of 10 individual sentences have sentiment correctly identified. Overall, using the metrics we design, the accuracy of AWS sentiment analysis for whole emails and individual sentences are calculated to be 52.64% and 23.02% respectively. Our results can be found in the same excel file as the output.\n",
    "\t\n",
    "### Conclusions\n",
    "In general, the sentiment analysis function does not perform well on both types of texts. Comparatively, it performed better on whole emails, which might be attributed to the fact that more context was given to aid understanding. However, the results we found have limitations as the expected score is calculated based on a small sample and contains variations among our group members since the labelings reflect judgements affected by personal experiences. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc07d25",
   "metadata": {},
   "source": [
    "## Targeted Sentiment Analysis\n",
    "### Hypotheses\n",
    "AWS Comprehend Targeted Sentiment Analysis will be able to accurately detect the sentiment of specific entities mentioned in a given sentence, even though the sentiment of the overall sentence might be different from the sentiment of specific entities within the sentence.\n",
    "\n",
    "\n",
    "### Experiment\n",
    "We continue our analysis with AWS targeted sentiment recognition. Our code to process the data can be found [here](https://github.com/Flora-Chen6/qtm350_project/blob/main/Codes/Amazon_Comprehend_Targeted_Sentiment_Test.ipynb).\n",
    "\n",
    "We followed the same procedure of labeling all data manually as we did for sentiment analysis. The only difference is that we gave each entity a score instead of each sentence/paragraph.\n",
    "\n",
    "After this, we organized the .json output file into a table and combined it with our manual labeling. Our output and expected output for individual sentences can be found [here](https://github.com/Flora-Chen6/qtm350_project/blob/main/Result/Target%20Sentiment%20Expected%20Score.xlsx).\n",
    "\n",
    "### Analysis\n",
    "We followed the same procedure of cleaning our data and calculating the accuracy as in Sentiment Analysis. The only difference is that we give each entity a score separately instead of the whole sentence.\n",
    "\n",
    "### Results\n",
    "Targeted Sentiment Analysis has an overall accuracy of 68.92%. In general, it’s a relatively low score, indicating that AWS Comprehend could not detect the sentiment accurately to some extent. Our results can be found in the same excel file as the output [here](https://github.com/Flora-Chen6/qtm350_project/blob/main/Result/Target%20Sentiment%20Expected%20Score.xlsx).\n",
    "\n",
    "### Conclusions\n",
    "Compared to Sentiment Analysis, Targeted sentiment analysis performed better when analyzing individual entities separately instead of the whole sentence. The reason might be that it’s easier to understand the individual entity and meet on an agreement. However, when it comes to the sentence, the mix of sentiment causes the confusion for both. \n",
    "\n",
    "As shown in our analysis, though individual entity within the sentence might be lablled as neutral, the sentiment of the whole sentence could be positive or negative regarding the context. In addition, it has a better chance to recognize neutral sentiment correctly when the expected output is neutral, which indicates that we still have divergence in understanding the meaning behind the words and it’s hard for AWS Comprehend to accurately detect negative and positive sentiment. \n",
    "\n",
    "We also found that the entity recognized in the Targeted Sentiment Analysis is different from that in the Entity Recognition, as there are more personal pronouns detected here which are not included in the Entity Recognition.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c64103",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "In general, we found the performance of the three services - Entity Recognition, Sentiment Analysis, and Targeted Sentiment Analysis - to be unsatisfactory based on the data we selected.\n",
    "\n",
    "Although Entity Recognition achieved a 77% accuracy in correctly labeling the entity to the correct category, it struggled to recognize most of the entities within a sentence. Specifically, it only identified 27% of the entities in our dataset, resulting in an overall accuracy of 18% for entity recognition.\n",
    "\n",
    "Sentiment Analysis performed the poorest out of the three services. It had an accuracy of 52.64% for whole emails, and even lower accuracy of 23.02% for individual sentences. However, it's worth noting that the difficulty in labeling our data with emotions that are hard to recognize could have contributed to this low performance.\n",
    "\n",
    "On the other hand, Targeted Sentiment Analysis performed better than Sentiment Analysis, achieving a significantly higher accuracy of 68.92%. It appears that the algorithm is better at identifying neutral sentiment compared to positive or negative sentiment, and its better performance may be explained by that most entities are neutral. Additionally, we noticed a discrepancy between the entities recognized by Entity Recognition and Targeted Sentiment Analysis, which requires further investigation.\n",
    "\n",
    "We acknowledge the limitations of our research, particularly the small size of our dataset, which could affect the reliability of our findings. In the future, it may be worth exploring AWS Comprehend's performance on different sources such as social media posts and newspapers, and comparing its performance on various text sources. Moreover, researchers could also investigate AWS Comprehend's performance in different languages besides English.\n",
    "\n",
    "In summary, our research concludes that AWS Comprehend's low accuracy cannot assist us in understanding emails. There is still room for improvement in various areas for AWS Comprehend."
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
